{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"atmacup0713.ipynb","provenance":[],"mount_file_id":"1uVA1Mt7eYULNJxxVHZZjZzbn22_gCsmR","authorship_tag":"ABX9TyO4HM6I7yxU+9OsJBBC9Km0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"thiW5zb2DxAZ"},"source":["import os\n","\n","import pandas as pd\n","import numpy as np\n","from glob import  glob\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erCLtF5MD9q6","executionInfo":{"status":"ok","timestamp":1626180311965,"user_tz":-540,"elapsed":7269,"user":{"displayName":"uuu muuu","photoUrl":"","userId":"14250301532849655136"}},"outputId":"c7679b21-b2c6-41df-b48c-61b20bf6a39a"},"source":["!pip install python-vivid\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting python-vivid\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/d7/0e733bc947a24e293fea88cd5cdd11004fd9b72ead1d2739c4ef58ba0be1/python_vivid-0.3.3.4-py3-none-any.whl (76kB)\n","\r\u001b[K     |████▎                           | 10kB 23.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 20kB 28.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 30kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 40kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 71kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.7MB/s \n","\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from python-vivid) (0.11.1)\n","Requirement already satisfied: feather-format in /usr/local/lib/python3.7/dist-packages (from python-vivid) (0.4.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from python-vivid) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from python-vivid) (0.22.2.post1)\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (from python-vivid) (2.2.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from python-vivid) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from python-vivid) (1.19.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from python-vivid) (2.5.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from python-vivid) (1.1.5)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from python-vivid) (1.0.1)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from python-vivid) (0.90)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from python-vivid) (0.8.9)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from python-vivid) (4.41.1)\n","Collecting optuna\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/18/b49ca91cf592747e19f2d333c2a86cd7c81895b922a5a09adf6335471576/optuna-2.8.0-py3-none-any.whl (301kB)\n","\u001b[K     |████████████████████████████████| 307kB 28.5MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from feather-format->python-vivid) (3.0.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->python-vivid) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->python-vivid) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->python-vivid) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->python-vivid) (1.3.1)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->python-vivid) (4.4.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->python-vivid) (2018.9)\n","Collecting alembic\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/80/ef186e599a57d0e4cb78fc76e0bfc2e6953fa9716b2a5cf2de0117ed8eb5/alembic-1.6.5-py2.py3-none-any.whl (164kB)\n","\u001b[K     |████████████████████████████████| 174kB 54.8MB/s \n","\u001b[?25hCollecting cmaes>=0.8.2\n","  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n","Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna->python-vivid) (1.4.20)\n","Collecting cliff\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/11/aea1cacbd4cf8262809c4d6f95dcb3f2802594de1f51c5bd454d69bf15c5/cliff-3.8.0-py3-none-any.whl (80kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.6MB/s \n","\u001b[?25hCollecting colorlog\n","  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna->python-vivid) (20.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->python-vivid) (1.15.0)\n","Collecting Mako\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n","\u001b[K     |████████████████████████████████| 81kB 12.0MB/s \n","\u001b[?25hCollecting python-editor>=0.3\n","  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n","Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->python-vivid) (1.1.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->python-vivid) (4.6.0)\n","Collecting cmd2>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/ca/d407811641ec1d8bd8a38ee3165d73aa44776d7700436bd4d4a6606f2736/cmd2-2.1.2-py3-none-any.whl (141kB)\n","\u001b[K     |████████████████████████████████| 143kB 53.3MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->python-vivid) (3.13)\n","Collecting pbr!=2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e0/1d4702dd81121d04a477c272d47ee5b6bc970d1a0990b11befa275c55cf2/pbr-5.6.0-py2.py3-none-any.whl (111kB)\n","\u001b[K     |████████████████████████████████| 112kB 56.2MB/s \n","\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->python-vivid) (2.1.0)\n","Collecting stevedore>=2.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna->python-vivid) (2.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna->python-vivid) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna->python-vivid) (3.4.1)\n","Collecting pyperclip>=1.6\n","  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n","Collecting colorama>=0.3.7\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->python-vivid) (0.2.5)\n","Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->python-vivid) (21.2.0)\n","Building wheels for collected packages: pyperclip\n","  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11136 sha256=7d8ffde6b466b515a91e7fe048c0080a571259584f69f400dd5318b186d1b539\n","  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n","Successfully built pyperclip\n","Installing collected packages: Mako, python-editor, alembic, cmaes, pyperclip, colorama, cmd2, pbr, stevedore, cliff, colorlog, optuna, python-vivid\n","Successfully installed Mako-1.1.4 alembic-1.6.5 cliff-3.8.0 cmaes-0.8.2 cmd2-2.1.2 colorama-0.4.4 colorlog-5.0.1 optuna-2.8.0 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 python-vivid-0.3.3.4 stevedore-3.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lVumQdMLEasD","executionInfo":{"status":"ok","timestamp":1626180311965,"user_tz":-540,"elapsed":5,"user":{"displayName":"uuu muuu","photoUrl":"","userId":"14250301532849655136"}},"outputId":"3526b1fe-3d35-44ee-db3d-7ae90e62ed5d"},"source":["%cd drive/\n","%cd MyDrive/dataset_atmaCup11/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive\n","/content/drive/MyDrive/dataset_atmaCup11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ldboF9OoD9x5"},"source":["dataset_root = \"./\"\n","assert dataset_root is not None\n","\n","input_dir = \"./input\"\n","photo_dir = \"./input/photos\"\n","\n","output_dir = os.path.join(dataset_root, \"outputs_tutorial#1\")\n","os.makedirs(output_dir, exist_ok=True)\n","\n","photo_pathes = glob(os.path.join(photo_dir, \"*.jpg\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j2jQN-WZD94g"},"source":["train_df = pd.read_csv(os.path.join(input_dir, 'train.csv'))\n","test_df = pd.read_csv(os.path.join(input_dir, 'test.csv'))\n","\n","material_df = pd.read_csv(os.path.join(input_dir, 'materials.csv'))\n","technique_df = pd.read_csv(os.path.join(input_dir, 'techniques.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"-9CZeS4uD99H","executionInfo":{"status":"ok","timestamp":1626180364194,"user_tz":-540,"elapsed":17,"user":{"displayName":"uuu muuu","photoUrl":"","userId":"14250301532849655136"}},"outputId":"98bf0dba-f577-4d80-d84e-aeb048d55a88"},"source":["train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>object_id</th>\n","      <th>sorting_date</th>\n","      <th>art_series_id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>002bff09b09998d0be65</td>\n","      <td>1631</td>\n","      <td>509357f67692a6a45626</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00309fb1ef05416f9c1f</td>\n","      <td>1900</td>\n","      <td>7987b47bbe5dc3039179</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>003a1562e97f79ba96dc</td>\n","      <td>1834</td>\n","      <td>ded7c3c9636708e5b14c</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>004890880e8e7431147b</td>\n","      <td>1743</td>\n","      <td>582ac2d7f0cef195b605</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00718c32602425f504c1</td>\n","      <td>1885</td>\n","      <td>64c907f0c08dce4fb8e8</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              object_id  sorting_date         art_series_id  target\n","0  002bff09b09998d0be65          1631  509357f67692a6a45626       1\n","1  00309fb1ef05416f9c1f          1900  7987b47bbe5dc3039179       3\n","2  003a1562e97f79ba96dc          1834  ded7c3c9636708e5b14c       3\n","3  004890880e8e7431147b          1743  582ac2d7f0cef195b605       2\n","4  00718c32602425f504c1          1885  64c907f0c08dce4fb8e8       3"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"CEgEPLqYD-Bk","executionInfo":{"status":"ok","timestamp":1626180364198,"user_tz":-540,"elapsed":19,"user":{"displayName":"uuu muuu","photoUrl":"","userId":"14250301532849655136"}},"outputId":"01709d17-86d2-4957-e99d-a94189125e5c"},"source":["test_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>object_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0009e50b94be36ccad39</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000bd5e82eb22f199f44</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0015f44de1854f617516</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00388a678879ba1efa27</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>005e1e7c6496902d23f3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              object_id\n","0  0009e50b94be36ccad39\n","1  000bd5e82eb22f199f44\n","2  0015f44de1854f617516\n","3  00388a678879ba1efa27\n","4  005e1e7c6496902d23f3"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"rCmYzZyLG9K8"},"source":["from PIL import Image\n","\n","def to_img_path(object_id):\n","    return os.path.join(photo_dir, f'{object_id}.jpg')\n","\n","def read_image(object_id):\n","    return Image.open(to_img_path(object_id))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"afSIqkcAHAGT"},"source":["from torchvision import transforms as T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eDVlpEgdHALp"},"source":["import torch\n","from torchvision.models import resnet34\n","from torch import nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rfWojMurHNmQ"},"source":["model = resnet34(pretrained=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jZwSPvcbHPT_"},"source":["converter = T.Compose([\n","    T.RandomVerticalFlip(p=1),\n","    T.ColorJitter(brightness=.5, contrast=.5),\n","    T.ToTensor()\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwPtyalqH2H0"},"source":["from torch.optim import Adam\n","\n","# 最適化手法の定義. どのモデルのパラメータを更新したいか、を第一引数にする\n","# lr は learning_rate の略. 正解はないのですが adam だと 1e-3 などが使われることが多いです\n","optimizer = Adam(params=model.parameters(), lr=1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VxPFn3p0II2a"},"source":["img = read_image(train_df['object_id'].iat[0])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h-tEUohrMZMS"},"source":["criterion = nn.MSELoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fzO1UOFPH4xS","executionInfo":{"status":"ok","timestamp":1626180369735,"user_tz":-540,"elapsed":651,"user":{"displayName":"uuu muuu","photoUrl":"","userId":"14250301532849655136"}},"outputId":"35dfbcf5-497a-4303-ef0e-6584397b3b18"},"source":["# 1. データを torch.Tensor の形式で用意\n","x = converter(img)\n","x = x.unsqueeze(0)\n","\n","label = train_df['target'].iat[0]\n","label = torch.Tensor([label])\n","label = label.reshape(-1, 1)\n","\n","# 2. モデルに入れて loss を objective で計算\n","output = model(x)\n","loss = criterion(output, label)\n","\n","# 3. loss から optimizer が model を更新\n","\n","# zero_grad は今ある勾配の情報をリセットする関数. このあとに計算される勾配を元にして最適化される\n","optimizer.zero_grad()\n","\n","# loss から勾配を計算\n","loss.backward()\n","\n","# 最適化ステップを一つすすめる\n","optimizer.step()\n","\n","print(loss.item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"],"name":"stderr"},{"output_type":"stream","text":["1.431814193725586\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDe4-U3PMcX0","executionInfo":{"status":"ok","timestamp":1626180370390,"user_tz":-540,"elapsed":657,"user":{"displayName":"uuu muuu","photoUrl":"","userId":"14250301532849655136"}},"outputId":"65673a6b-d3a0-42dc-be5a-5755e7a31634"},"source":["from torch.optim import Adam\n","\n","# 最適化手法の定義. どのモデルのパラメータを更新したいか、を第一引数にする\n","# lr は learning_rate の略. 正解はないのですが adam だと 1e-3 などが使われることが多いです\n","optimizer = Adam(params=model.parameters(), lr=1e-3)\n","\n","x = converter(img)\n","x = x.unsqueeze(0)\n","\n","label = train_df['target'].iat[0]\n","label = torch.Tensor([label])\n","label = label.reshape(-1, 1)\n","\n","# 2. モデルに入れて loss を objective で計算\n","output = model(x)\n","loss = criterion(output, label)\n","\n","# 3. loss から optimizer が model を更新\n","\n","# zero_grad は今ある勾配の情報をリセットする関数. このあとに計算される勾配を元にして最適化される\n","optimizer.zero_grad()\n","\n","# loss から勾配を計算\n","loss.backward()\n","\n","# 最適化ステップを一つすすめる\n","optimizer.step()\n","\n","print(loss.item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"],"name":"stderr"},{"output_type":"stream","text":["0.5776651501655579\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aDTE55uDMsoT"},"source":["from torch.utils import data\n","\n","IMG_MEAN = [0.485, 0.456, 0.406]\n","IMG_STD = [0.229, 0.224, 0.225]\n","\n","class AtmaDataset(data.Dataset):\n","    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n","    object_path_key = \"object_path\"\n","    label_key = \"target\"\n","\n","    @property\n","    def meta_keys(self):\n","        retval = [self.object_path_key]\n","\n","        if self.is_train:\n","            retval += [self.label_key]\n","\n","        return retval\n","\n","    def __init__(self, meta_df: pd.DataFrame, is_train=True):\n","        \"\"\"\n","        args:\n","            meta_df: \n","                画像へのパスと label 情報が含まれている dataframe\n","                必ず object_path に画像へのパス, target に正解ラベルが入っている必要があります\n","\n","            is_train:\n","                True のとき学習用のデータ拡張を適用します.\n","                False の時は単に size にリサイズを行います\n","        \"\"\"\n","\n","        self.is_train = is_train\n","        for k in self.meta_keys:\n","            if k not in meta_df:\n","                raise ValueError(\"meta df must have {}\".format(k))\n","\n","        self.meta_df = meta_df.reset_index(drop=True)\n","        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n","\n","        size = (224, 224)\n","\n","        additional_items = (\n","            [T.Resize(size)]\n","            if not is_train\n","            else [\n","                T.RandomGrayscale(p=0.2),\n","                T.RandomVerticalFlip(),\n","                T.RandomHorizontalFlip(),\n","                T.ColorJitter(\n","                    brightness=0.3,\n","                    contrast=0.5,\n","                    saturation=[0.8, 1.3],\n","                    hue=[-0.05, 0.05],\n","                ),\n","                T.RandomResizedCrop(size),\n","            ]\n","        )\n","\n","        self.transformer = T.Compose(\n","            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n","        )\n","\n","    def __getitem__(self, index):\n","        data = self.index_to_data[index]\n","\n","        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n","        img = Image.open(obj_path)\n","        img = self.transformer(img)\n","        return img, label\n","\n","    def __len__(self):\n","        return len(self.meta_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FgRh9wTbMtlI"},"source":["train_meta_df = train_df[['target', 'object_id']].copy()\n","train_meta_df['object_path'] = train_meta_df['object_id'].map(to_img_path)\n","\n","dataset = AtmaDataset(meta_df=train_meta_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYcTwkGrN7qC","executionInfo":{"status":"ok","timestamp":1626180370391,"user_tz":-540,"elapsed":9,"user":{"displayName":"uuu muuu","photoUrl":"","userId":"14250301532849655136"}},"outputId":"39048571-2222-4efe-90b5-cc1f2ff133af"},"source":["loader = data.DataLoader(dataset=dataset, batch_size=54, num_workers=4)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PVfIkWeINEof"},"source":["assert torch.cuda.is_available()\n","\n","DEVICE = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0BNK5u5eNYZ-"},"source":["from torch.optim.optimizer import Optimizer\n","from collections import defaultdict\n","\n","def train(\n","    model: nn.Module,\n","    optimizer: Optimizer,\n","    train_loader: data.DataLoader\n",") -> pd.Series:\n","\n","    # train にすることで model 内の学習時にのみ有効な機構が有効になります (Dropouts Layers、BatchNorm Layers...)\n","    model.train()\n","\n","    criterion = nn.MSELoss()\n","\n","    # ロスの値を保存する用に dict を用意\n","    metrics = defaultdict(float)\n","    n_iters = len(train_loader)\n","\n","    for i, (x_i, y_i) in enumerate(train_loader):\n","        x_i = x_i.to(DEVICE)\n","        y_i = y_i.to(DEVICE).reshape(-1, 1).float()\n","\n","        output = model(x_i)\n","        loss = criterion(output, y_i)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        metric_i = {\n","            # loss は tensor object なので item をつかって python object に戻す\n","            \"loss\": loss.item()\n","        }\n","        for k, v in metric_i.items():\n","            metrics[k] += v\n","\n","    for k, v in metrics.items():\n","        metrics[k] /= n_iters\n","\n","    return pd.Series(metrics).add_prefix(\"train_\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06FTCQewNb_h","executionInfo":{"status":"ok","timestamp":1626180652241,"user_tz":-540,"elapsed":281855,"user":{"displayName":"uuu muuu","photoUrl":"","userId":"14250301532849655136"}},"outputId":"ded50c21-4cce-453a-ee1a-350b89c1aa7c"},"source":["from vivid.utils import timer\n","\n","n_epochs = 10\n","\n","# GPU 環境で学習するため変換. この呼び出しは破壊的\n","model.to(DEVICE)\n","optimizer = Adam(params=model.parameters(), lr=1e-3)\n","\n","for epoch in range(1, n_epochs + 1):\n","\n","    with timer(prefix=\"train: epoch={}\".format(epoch)):\n","        score_train = train(\n","            model, optimizer, train_loader=loader\n","        )\n","    print(score_train)\n","\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([54, 1])) that is different to the input size (torch.Size([54, 1000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([49, 1])) that is different to the input size (torch.Size([49, 1000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"],"name":"stderr"},{"output_type":"stream","text":["train: epoch=1 269.534[s]\n","train_loss    1.022512\n","dtype: float64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o-m4vjYO66uq"},"source":["from sklearn.model_selection import KFold\n","\n","fold = KFold(n_splits=5, shuffle=True, random_state=510)\n","cv = list(fold.split(X=train_df, y=train_df['target']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yy8yrdVr7Bfn"},"source":["from sklearn.metrics import mean_squared_error\n","\n","\n","def predict(model: nn.Module, loader: data.DataLoader) -> np.ndarray:\n","    # train とは逆で model 内の学習時にのみ有効な機構がオフになります (Dropouts Layers、BatchNorm Layers...)\n","    model.eval()\n","\n","    predicts = []\n","\n","    for x_i, y_i in loader:\n","\n","        # 明示的に勾配を計算しないように指定することができます. \n","        # この関数ではモデルの更新はせずに単に出力だけを使いますので勾配は不要です.\n","        with torch.no_grad():\n","            output = model(x_i.to(DEVICE))\n","\n","        predicts.extend(output.data.cpu().numpy())\n","\n","    pred = np.array(predicts).reshape(-1)\n","    return pred\n","\n","\n","def calculate_metrics(y_true, y_pred) -> dict:\n","    \"\"\"正解ラベルと予測ラベルから指標を計算する\"\"\"\n","    # return regression_metrics(y_true, y_pred)\n","\n","    return {\n","        'rmse': mean_squared_error(y_true, y_pred) ** .5\n","    }\n","\n","\n","def valid(\n","    model: nn.Module, \n","    y_valid: np.ndarray, \n","    valid_loader: data.DataLoader\n",") -> pd.Series:\n","    \"\"\"検証フェーズ\n","    与えられたモデル・データローダを使って検証フェーズを実行。スコアの dict と予測した値を返す\n","    \"\"\"\n","\n","    pred = predict(model, valid_loader)\n","    score = calculate_metrics(y_valid, pred)\n","\n","    valid_score = pd.Series(score)\n","    return valid_score.add_prefix(\"valid_\"), pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UvDIr2Vn7Itj"},"source":["from tabulate import tabulate\n","\n","\n","def run_fold(\n","    model: nn.Module, \n","    train_df: pd.DataFrame, \n","    valid_df: pd.DataFrame, \n","    y_valid: np.ndarray, \n","    output_dir: str, \n","    n_epochs=30) -> np.ndarray:\n","    \"\"\"\n","    train / valid に分割されたデータで学習と同時に検証を行なう\n","    \"\"\"\n","\n","    os.makedirs(output_i, exist_ok=True)\n","\n","    optimizer = Adam(model.parameters(), lr=1e-3)\n","\n","    # 0: 前準備. dataframe から data loader を作成\n","    train_dataset = AtmaDataset(meta_df=train_df)\n","    # 検証用の方は is_train=False にしてデータ拡張オフにする\n","    valid_dataset = AtmaDataset(meta_df=valid_df, is_train=False)\n","\n","    train_loader = data.DataLoader(\n","        train_dataset, batch_size=64, shuffle=True, drop_last=True, num_workers=4\n","    )\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=256, num_workers=4)\n","\n","    # --- 保存のための変数定義\n","    score_df = pd.DataFrame()\n","    valid_score = np.inf\n","    valid_score_key = \"valid_rmse\"\n","    valid_best_pred = None\n","\n","    for epoch in range(1, n_epochs + 1):\n","        print(f'start {epoch}')\n","\n","        # 1: 学習用データで学習を実行。学習時のロスを取得\n","        with timer(prefix=\"train: epoch={}\".format(epoch)):\n","            score_train = train(\n","                model, optimizer, train_loader\n","            )\n","\n","        # 2: 検証データでのスコアを計算\n","        with timer(prefix=\"validate\"):\n","            score_valid, y_valid_pred = valid(model=model, valid_loader=valid_loader, y_valid=y_valid)\n","\n","\n","        # --- 学習のロスと検証スコアの値をデータフレームに追加\n","        row = pd.concat([score_train, score_valid])\n","        row[\"epoch\"] = epoch\n","        row = pd.DataFrame([row])\n","        print(tabulate(row, headers=row.columns))\n","        score_df = pd.concat([score_df, row], ignore_index=True)\n","        # ---\n","\n","        # 今の検証スコアと過去最高のスコアを比較\n","        current_score = score_valid[valid_score_key]\n","        if current_score < valid_score:\n","            # スコア改善したときモデルを保存する\n","            print(f'validation score is improved!! {valid_score:.4f} -> {current_score:.4f}')\n","            torch.save(\n","                model.state_dict(), os.path.join(output_dir, 'model_best.pth')\n","            )\n","            valid_score = current_score\n","            valid_best_pred = y_valid_pred\n","\n","    score_df.to_csv(os.path.join(output_dir, 'score.csv'), index=False)\n","    return valid_best_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L0uNEBeQ7Mkt","executionInfo":{"status":"ok","timestamp":1626180872711,"user_tz":-540,"elapsed":127692,"user":{"displayName":"uuu muuu","photoUrl":"","userId":"14250301532849655136"}},"outputId":"a0dec953-164f-4f21-b9ff-be989d412d11"},"source":["def get_output_dir(n_cv: int):\n","    return os.path.join(output_dir, 'simple_resnet', f'cv={n_cv}')\n","\n","oof = np.zeros((len(train_df), ), dtype=np.float32)\n","\n","for i, (idx_tr, idx_valid) in enumerate(cv):\n","    output_i = get_output_dir(i)\n","    model = resnet34(pretrained=False)\n","    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n","\n","    model.to(DEVICE)\n","\n","    oof_i = run_fold(\n","        model=model, \n","        train_df=train_meta_df.iloc[idx_tr], \n","        valid_df=train_meta_df.iloc[idx_valid], \n","        y_valid=train_meta_df['target'].values[idx_valid],\n","        output_dir=output_i,\n","\n","        # 今は 1 ですぐ終わるようにしている. 本当は validation score の値を見つつ適宜設定する\n","        n_epochs=1\n","    )\n","\n","    oof[idx_valid] = oof_i"],"execution_count":null,"outputs":[{"output_type":"stream","text":["start 1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["train: epoch=1 21.326[s]\n","validate 3.462[s]\n","      train_loss    valid_rmse    epoch\n","--  ------------  ------------  -------\n"," 0       2.19731       1.06098        1\n","validation score is improved!! inf -> 1.0610\n","start 1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["train: epoch=1 21.434[s]\n","validate 3.536[s]\n","      train_loss    valid_rmse    epoch\n","--  ------------  ------------  -------\n"," 0       3.50221      0.959103        1\n","validation score is improved!! inf -> 0.9591\n","start 1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["train: epoch=1 21.411[s]\n","validate 3.489[s]\n","      train_loss    valid_rmse    epoch\n","--  ------------  ------------  -------\n"," 0        3.4159      0.963705        1\n","validation score is improved!! inf -> 0.9637\n","start 1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["train: epoch=1 21.400[s]\n","validate 3.360[s]\n","      train_loss    valid_rmse    epoch\n","--  ------------  ------------  -------\n"," 0       1.86185      0.992649        1\n","validation score is improved!! inf -> 0.9926\n","start 1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["train: epoch=1 21.406[s]\n","validate 3.476[s]\n","      train_loss    valid_rmse    epoch\n","--  ------------  ------------  -------\n"," 0       2.99325      0.965935        1\n","validation score is improved!! inf -> 0.9659\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pshwq1R97jc-","executionInfo":{"status":"ok","timestamp":1626180872715,"user_tz":-540,"elapsed":13,"user":{"displayName":"uuu muuu","photoUrl":"","userId":"14250301532849655136"}},"outputId":"1441f7d4-a77e-4647-f496-68f9a56fc2ba"},"source":["calculate_metrics(train_df['target'], oof)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'rmse': 0.9892200337461046}"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eahqr2Hb7rju","executionInfo":{"status":"ok","timestamp":1626180872715,"user_tz":-540,"elapsed":10,"user":{"displayName":"uuu muuu","photoUrl":"","userId":"14250301532849655136"}},"outputId":"830e539a-0005-4a52-86d3-22e4f4ae8017"},"source":["def create_metadata(input_df):\n","    out_df = input_df[['object_id']].copy()\n","    out_df['object_path'] = input_df['object_id'].map(to_img_path)\n","\n","    if \"target\" in input_df:\n","        out_df[\"target\"] = input_df[\"target\"]\n","\n","    return out_df\n","\n","# train と似たようなことをするので、次回から楽したいとおもって `create_metadata` という関数を作りました\n","test_meta_df = create_metadata(test_df)\n","\n","# 学習時のデータ拡張はオフにしたいので is_train=False としている\n","test_dataset = AtmaDataset(meta_df=test_meta_df, is_train=False)\n","test_loader = data.DataLoader(dataset=test_dataset, batch_size=128, drop_last=False, num_workers=4)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkH7NZGb7uGO","executionInfo":{"status":"ok","timestamp":1626181334022,"user_tz":-540,"elapsed":459722,"user":{"displayName":"uuu muuu","photoUrl":"","userId":"14250301532849655136"}},"outputId":"53ff2aff-4940-49e6-81d0-b58f551336af"},"source":["test_predictions = []\n","\n","for i in range(len(cv)):\n","    output_i = get_output_dir(i)\n","\n","    model = resnet34(pretrained=False)\n","    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n","\n","    # 最も良かった重みを読みだす\n","    # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n","    model_path = os.path.join(output_i, 'model_best.pth')\n","\n","    model.load_state_dict(torch.load(model_path))\n","\n","    # GPU環境で予測するため `to` で変換\n","    model.to(DEVICE)\n","\n","    with timer(prefix=f'pred cv={i}'):\n","        y_pred_i = predict(model, loader=test_loader)\n","\n","    test_predictions.append(y_pred_i)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["pred cv=0 394.839[s]\n","pred cv=1 15.615[s]\n","pred cv=2 15.491[s]\n","pred cv=3 15.436[s]\n","pred cv=4 15.534[s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z0JYlBeU7vi2"},"source":["# すべての予測の平均値を使う\n","pred_mean = np.array(test_predictions).mean(axis=0)\n","\n","pd.DataFrame({\n","    \"target\": pred_mean\n","}).to_csv(os.path.join(output_dir, \"0001__submission.csv\"), index=False)"],"execution_count":null,"outputs":[]}]}